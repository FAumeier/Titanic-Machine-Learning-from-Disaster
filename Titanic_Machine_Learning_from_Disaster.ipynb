{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"data\"\n",
    "train_fn = \"train.csv\"\n",
    "test_fn = \"test.csv\"\n",
    "train_path = os.path.join(data_dir, train_fn)\n",
    "test_path = os.path.join(data_dir, test_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definition of the CategoricalEncoder class, copied from PR #9151.\n",
    "# Just run this cell, or copy it to your code, do not try to understand it (yet).\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Encode categorical features as a numeric array.\n",
    "    The input to this transformer should be a matrix of integers or strings,\n",
    "    denoting the values taken on by categorical (discrete) features.\n",
    "    The features can be encoded using a one-hot aka one-of-K scheme\n",
    "    (``encoding='onehot'``, the default) or converted to ordinal integers\n",
    "    (``encoding='ordinal'``).\n",
    "    This encoding is needed for feeding categorical data to many scikit-learn\n",
    "    estimators, notably linear models and SVMs with the standard kernels.\n",
    "    Read more in the :ref:`User Guide <preprocessing_categorical_features>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    encoding : str, 'onehot', 'onehot-dense' or 'ordinal'\n",
    "        The type of encoding to use (default is 'onehot'):\n",
    "        - 'onehot': encode the features using a one-hot aka one-of-K scheme\n",
    "          (or also called 'dummy' encoding). This creates a binary column for\n",
    "          each category and returns a sparse matrix.\n",
    "        - 'onehot-dense': the same as 'onehot' but returns a dense array\n",
    "          instead of a sparse matrix.\n",
    "        - 'ordinal': encode the features as ordinal integers. This results in\n",
    "          a single column of integers (0 to n_categories - 1) per feature.\n",
    "    categories : 'auto' or a list of lists/arrays of values.\n",
    "        Categories (unique values) per feature:\n",
    "        - 'auto' : Determine categories automatically from the training data.\n",
    "        - list : ``categories[i]`` holds the categories expected in the ith\n",
    "          column. The passed categories are sorted before encoding the data\n",
    "          (used categories can be found in the ``categories_`` attribute).\n",
    "    dtype : number type, default np.float64\n",
    "        Desired dtype of output.\n",
    "    handle_unknown : 'error' (default) or 'ignore'\n",
    "        Whether to raise an error or ignore if a unknown categorical feature is\n",
    "        present during transform (default is to raise). When this is parameter\n",
    "        is set to 'ignore' and an unknown category is encountered during\n",
    "        transform, the resulting one-hot encoded columns for this feature\n",
    "        will be all zeros.\n",
    "        Ignoring unknown categories is not supported for\n",
    "        ``encoding='ordinal'``.\n",
    "    Attributes\n",
    "    ----------\n",
    "    categories_ : list of arrays\n",
    "        The categories of each feature determined during fitting. When\n",
    "        categories were specified manually, this holds the sorted categories\n",
    "        (in order corresponding with output of `transform`).\n",
    "    Examples\n",
    "    --------\n",
    "    Given a dataset with three features and two samples, we let the encoder\n",
    "    find the maximum value per feature and transform the data to a binary\n",
    "    one-hot encoding.\n",
    "    >>> from sklearn.preprocessing import CategoricalEncoder\n",
    "    >>> enc = CategoricalEncoder(handle_unknown='ignore')\n",
    "    >>> enc.fit([[0, 0, 3], [1, 1, 0], [0, 2, 1], [1, 0, 2]])\n",
    "    ... # doctest: +ELLIPSIS\n",
    "    CategoricalEncoder(categories='auto', dtype=<... 'numpy.float64'>,\n",
    "              encoding='onehot', handle_unknown='ignore')\n",
    "    >>> enc.transform([[0, 1, 1], [1, 0, 4]]).toarray()\n",
    "    array([[ 1.,  0.,  0.,  1.,  0.,  0.,  1.,  0.,  0.],\n",
    "           [ 0.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.]])\n",
    "    See also\n",
    "    --------\n",
    "    sklearn.preprocessing.OneHotEncoder : performs a one-hot encoding of\n",
    "      integer ordinal features. The ``OneHotEncoder assumes`` that input\n",
    "      features take on values in the range ``[0, max(feature)]`` instead of\n",
    "      using the unique values.\n",
    "    sklearn.feature_extraction.DictVectorizer : performs a one-hot encoding of\n",
    "      dictionary items (also handles string-valued features).\n",
    "    sklearn.feature_extraction.FeatureHasher : performs an approximate one-hot\n",
    "      encoding of dictionary items or strings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"Fit the CategoricalEncoder to X.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_feature]\n",
    "            The data to determine the categories of each feature.\n",
    "        Returns\n",
    "        -------\n",
    "        self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform X using one-hot encoding.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape [n_samples, n_features]\n",
    "            The data to encode.\n",
    "        Returns\n",
    "        -------\n",
    "        X_out : sparse matrix or a 2-d array\n",
    "            Transformed input.\n",
    "        \"\"\"\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    # Set the problematic rows to an acceptable value and\n",
    "                    # continue `The rows are marked `X_mask` and will be\n",
    "                    # removed later.\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the numnber of occurances of each operator\n",
    "survived_counts = train_data.Survived.value_counts()\n",
    "\n",
    "# Split and Save the Operator names in a variable\n",
    "ids = survived_counts.index\n",
    "\n",
    "# Split and Save the counts in another variable\n",
    "counts = survived_counts.get_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAD3CAYAAADi8sSvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1423e6baf28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create barplot object\n",
    "barplot = sns.barplot(x=ids, y=counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1423c9aacc0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEFCAYAAADqujDUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1423dd490f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_num = train_data.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare'], dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_num.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_num = train_data_num.drop(['PassengerId', 'Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "train_data_num_tr = num_pipeline.fit_transform(train_data_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# Create a class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names].astype(str).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_attribs = list(train_data_num)\n",
    "cat_attribs = [\"Sex\", \"Ticket\", \"Cabin\", \"Embarked\"]\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(num_attribs)),\n",
    "        ('imputer', Imputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "        ('selector', DataFrameSelector(cat_attribs)),\n",
    "        ('cat_encoder', CategoricalEncoder(encoding=\"onehot-dense\", handle_unknown='ignore')),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_data['Survived']\n",
    "train_data = train_data.drop(['PassengerId', 'Survived', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline),\n",
    "        (\"cat_pipeline\", cat_pipeline),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_prepared = full_pipeline.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]}, {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5,\n",
    "                           scoring='f1')\n",
    "grid_search.fit(train_data_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 8, 'n_estimators': 30}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=8, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=30, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684806015988 {'max_features': 2, 'n_estimators': 3}\n",
      "0.736610044032 {'max_features': 2, 'n_estimators': 10}\n",
      "0.754547262562 {'max_features': 2, 'n_estimators': 30}\n",
      "0.713836811486 {'max_features': 4, 'n_estimators': 3}\n",
      "0.744265807066 {'max_features': 4, 'n_estimators': 10}\n",
      "0.761161665835 {'max_features': 4, 'n_estimators': 30}\n",
      "0.697962116154 {'max_features': 6, 'n_estimators': 3}\n",
      "0.734903390976 {'max_features': 6, 'n_estimators': 10}\n",
      "0.762573126139 {'max_features': 6, 'n_estimators': 30}\n",
      "0.701281800045 {'max_features': 8, 'n_estimators': 3}\n",
      "0.758282632694 {'max_features': 8, 'n_estimators': 10}\n",
      "0.763070413936 {'max_features': 8, 'n_estimators': 30}\n",
      "0.708705276748 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.729931300056 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.720676651492 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.734713835081 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.705718084114 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.746685857336 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'n_estimators': [3, 10, 30, 50, 70, 90, 110], 'max_features': [2, 4, 6, 8, 10, 12, 14]}, {'bootstrap': [False], 'n_estimators': [3, 10, 20], 'max_features': [2, 3, 4, 5, 6]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='f1', verbose=0)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30, 50, 70, 90, 110], 'max_features': [2, 4, 6, 8, 10, 12, 14]},\n",
    "    # then try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10, 20], 'max_features': [2, 3, 4, 5, 6]},\n",
    "  ]\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "# train across 5 folds, that's a total of (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_clf, param_grid, cv=5,\n",
    "                           scoring='f1')\n",
    "grid_search.fit(train_data_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 90}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=90, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.684806015988 {'max_features': 2, 'n_estimators': 3}\n",
      "0.736610044032 {'max_features': 2, 'n_estimators': 10}\n",
      "0.754547262562 {'max_features': 2, 'n_estimators': 30}\n",
      "0.757640838526 {'max_features': 2, 'n_estimators': 50}\n",
      "0.767512665335 {'max_features': 2, 'n_estimators': 70}\n",
      "0.765727947722 {'max_features': 2, 'n_estimators': 90}\n",
      "0.766990450904 {'max_features': 2, 'n_estimators': 110}\n",
      "0.713836811486 {'max_features': 4, 'n_estimators': 3}\n",
      "0.744265807066 {'max_features': 4, 'n_estimators': 10}\n",
      "0.761161665835 {'max_features': 4, 'n_estimators': 30}\n",
      "0.765707342983 {'max_features': 4, 'n_estimators': 50}\n",
      "0.771194817591 {'max_features': 4, 'n_estimators': 70}\n",
      "0.768273248379 {'max_features': 4, 'n_estimators': 90}\n",
      "0.770056330061 {'max_features': 4, 'n_estimators': 110}\n",
      "0.697962116154 {'max_features': 6, 'n_estimators': 3}\n",
      "0.734903390976 {'max_features': 6, 'n_estimators': 10}\n",
      "0.762573126139 {'max_features': 6, 'n_estimators': 30}\n",
      "0.778814636024 {'max_features': 6, 'n_estimators': 50}\n",
      "0.781543613044 {'max_features': 6, 'n_estimators': 70}\n",
      "0.781871578357 {'max_features': 6, 'n_estimators': 90}\n",
      "0.769928525777 {'max_features': 6, 'n_estimators': 110}\n",
      "0.701281800045 {'max_features': 8, 'n_estimators': 3}\n",
      "0.758282632694 {'max_features': 8, 'n_estimators': 10}\n",
      "0.763070413936 {'max_features': 8, 'n_estimators': 30}\n",
      "0.764810236795 {'max_features': 8, 'n_estimators': 50}\n",
      "0.768519037851 {'max_features': 8, 'n_estimators': 70}\n",
      "0.770898916253 {'max_features': 8, 'n_estimators': 90}\n",
      "0.773336997374 {'max_features': 8, 'n_estimators': 110}\n",
      "0.719203562498 {'max_features': 10, 'n_estimators': 3}\n",
      "0.745544565062 {'max_features': 10, 'n_estimators': 10}\n",
      "0.774938203344 {'max_features': 10, 'n_estimators': 30}\n",
      "0.76483762439 {'max_features': 10, 'n_estimators': 50}\n",
      "0.758229744606 {'max_features': 10, 'n_estimators': 70}\n",
      "0.764503422372 {'max_features': 10, 'n_estimators': 90}\n",
      "0.763843695749 {'max_features': 10, 'n_estimators': 110}\n",
      "0.697074178438 {'max_features': 12, 'n_estimators': 3}\n",
      "0.750046720506 {'max_features': 12, 'n_estimators': 10}\n",
      "0.763146813522 {'max_features': 12, 'n_estimators': 30}\n",
      "0.762830730846 {'max_features': 12, 'n_estimators': 50}\n",
      "0.76528162407 {'max_features': 12, 'n_estimators': 70}\n",
      "0.760536450852 {'max_features': 12, 'n_estimators': 90}\n",
      "0.769056721185 {'max_features': 12, 'n_estimators': 110}\n",
      "0.715211657 {'max_features': 14, 'n_estimators': 3}\n",
      "0.727560254031 {'max_features': 14, 'n_estimators': 10}\n",
      "0.767590086321 {'max_features': 14, 'n_estimators': 30}\n",
      "0.772158327479 {'max_features': 14, 'n_estimators': 50}\n",
      "0.770479768455 {'max_features': 14, 'n_estimators': 70}\n",
      "0.76384323548 {'max_features': 14, 'n_estimators': 90}\n",
      "0.760607757498 {'max_features': 14, 'n_estimators': 110}\n",
      "0.708705276748 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "0.729931300056 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "0.744990134078 {'bootstrap': False, 'max_features': 2, 'n_estimators': 20}\n",
      "0.720676651492 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "0.734713835081 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "0.757247556683 {'bootstrap': False, 'max_features': 3, 'n_estimators': 20}\n",
      "0.705718084114 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "0.746685857336 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n",
      "0.75869957853 {'bootstrap': False, 'max_features': 4, 'n_estimators': 20}\n",
      "0.739543744545 {'bootstrap': False, 'max_features': 5, 'n_estimators': 3}\n",
      "0.769517677723 {'bootstrap': False, 'max_features': 5, 'n_estimators': 10}\n",
      "0.771958395112 {'bootstrap': False, 'max_features': 5, 'n_estimators': 20}\n",
      "0.67893344133 {'bootstrap': False, 'max_features': 6, 'n_estimators': 3}\n",
      "0.747128894755 {'bootstrap': False, 'max_features': 6, 'n_estimators': 10}\n",
      "0.778973876424 {'bootstrap': False, 'max_features': 6, 'n_estimators': 20}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=42, verbose=0, warm_start=False),\n",
       "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000014240C53080>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000014240C53D68>},\n",
       "          pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "          return_train_score=True, scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_clf, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='accuracy', random_state=42)\n",
    "rnd_search.fit(train_data_prepared, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83950617284 {'max_features': 7, 'n_estimators': 180}\n",
      "0.826038159371 {'max_features': 5, 'n_estimators': 15}\n",
      "0.838383838384 {'max_features': 3, 'n_estimators': 72}\n",
      "0.83164983165 {'max_features': 5, 'n_estimators': 21}\n",
      "0.838383838384 {'max_features': 7, 'n_estimators': 122}\n",
      "0.835016835017 {'max_features': 3, 'n_estimators': 75}\n",
      "0.836139169473 {'max_features': 3, 'n_estimators': 88}\n",
      "0.824915824916 {'max_features': 5, 'n_estimators': 100}\n",
      "0.840628507295 {'max_features': 3, 'n_estimators': 150}\n",
      "0.775533108866 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(mean_score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.80437112e-02,   7.35877463e-02,   2.57078056e-02,\n",
       "         2.18368720e-02,   8.02606407e-02,   9.62072028e-02,\n",
       "         8.42021424e-02,   1.17665123e-03,   5.50302883e-04,\n",
       "         7.10663411e-04,   9.58327156e-04,   1.90562617e-04,\n",
       "         3.40436975e-04,   2.83434385e-04,   6.53137086e-04,\n",
       "         7.94045936e-04,   1.38034809e-03,   1.83799908e-03,\n",
       "         1.60298259e-03,   2.28615841e-04,   2.10872829e-04,\n",
       "         4.60209010e-04,   2.60521202e-04,   2.49341075e-04,\n",
       "         5.98694702e-04,   3.30217072e-04,   2.04647808e-04,\n",
       "         2.68176368e-04,   3.17110633e-04,   3.67138784e-04,\n",
       "         6.89740979e-04,   2.89223577e-04,   4.65425179e-04,\n",
       "         4.26904018e-04,   3.03014838e-04,   7.04241263e-04,\n",
       "         4.89710223e-04,   2.66376358e-04,   1.55622163e-04,\n",
       "         4.66989567e-04,   1.60133248e-03,   3.04734603e-04,\n",
       "         3.17257030e-04,   3.68789632e-04,   1.88035031e-03,\n",
       "         4.48987786e-04,   2.63831385e-04,   7.70285425e-04,\n",
       "         2.58571124e-04,   8.64694113e-04,   6.13083945e-04,\n",
       "         3.27070386e-04,   1.81397089e-03,   4.06291896e-04,\n",
       "         7.98718564e-04,   3.30098905e-04,   4.83999518e-04,\n",
       "         1.44519617e-03,   1.04032054e-03,   3.45926542e-04,\n",
       "         1.28378344e-03,   7.52381071e-04,   2.96390830e-04,\n",
       "         8.06282260e-04,   2.54004832e-04,   5.14466854e-04,\n",
       "         8.46875577e-04,   3.66162551e-04,   3.86088210e-04,\n",
       "         8.39227510e-04,   2.94966726e-04,   7.51923117e-04,\n",
       "         2.38483134e-04,   1.91833006e-04,   8.03642158e-04,\n",
       "         3.87088424e-04,   9.11198578e-04,   6.16218051e-04,\n",
       "         1.14323295e-03,   4.13034337e-04,   3.02414884e-04,\n",
       "         5.95923872e-04,   3.15956527e-04,   1.00455734e-03,\n",
       "         1.01671434e-03,   9.68465178e-04,   1.47401148e-04,\n",
       "         4.55215234e-03,   4.48551064e-04,   1.03033379e-03,\n",
       "         1.18300679e-03,   1.01745771e-03,   4.19734972e-04,\n",
       "         4.71059715e-04,   4.51429261e-04,   4.83341241e-04,\n",
       "         1.14207000e-03,   4.49262186e-04,   9.29233856e-04,\n",
       "         4.47045349e-04,   1.05919371e-03,   1.18419665e-03,\n",
       "         4.74360960e-04,   7.91375067e-04,   2.38932623e-04,\n",
       "         1.04908321e-03,   1.60970536e-03,   6.86879524e-04,\n",
       "         1.50855822e-04,   1.37039882e-04,   1.62321734e-04,\n",
       "         1.74019409e-04,   2.10873291e-04,   1.45386725e-03,\n",
       "         1.54850440e-04,   6.88890337e-04,   3.20377539e-04,\n",
       "         8.18031946e-04,   6.96703100e-04,   1.87035532e-04,\n",
       "         6.91625680e-04,   8.53481859e-04,   1.35843413e-03,\n",
       "         5.86361284e-04,   1.06835531e-03,   2.38178292e-04,\n",
       "         2.39476716e-04,   9.55842891e-05,   2.32940392e-04,\n",
       "         9.28290173e-04,   1.73747339e-04,   7.58985689e-04,\n",
       "         2.60200430e-04,   1.01333050e-03,   3.15512920e-04,\n",
       "         1.14314085e-04,   1.84600530e-04,   7.04361439e-04,\n",
       "         1.40838186e-03,   4.56147937e-04,   6.05016815e-04,\n",
       "         2.49339385e-03,   5.64623870e-04,   1.84982931e-04,\n",
       "         1.41604722e-04,   1.30830333e-04,   6.25824714e-04,\n",
       "         7.28195199e-04,   1.55483721e-03,   6.59157865e-04,\n",
       "         7.89507489e-04,   1.48796423e-03,   2.78135885e-03,\n",
       "         1.34612774e-04,   2.26987023e-04,   2.30826069e-04,\n",
       "         2.23070832e-04,   5.50553825e-04,   2.72958793e-03,\n",
       "         7.78706152e-04,   1.11906737e-03,   2.16384753e-04,\n",
       "         8.91959356e-04,   2.33022172e-04,   4.36772297e-04,\n",
       "         1.46655965e-03,   2.61186316e-04,   1.77058688e-03,\n",
       "         2.88369496e-04,   1.46400460e-03,   1.82663242e-04,\n",
       "         3.64762322e-04,   7.84839363e-04,   1.43785297e-03,\n",
       "         1.37538613e-03,   7.25108634e-04,   1.91487047e-04,\n",
       "         7.31114611e-04,   2.02331029e-03,   1.40180405e-04,\n",
       "         1.88161883e-04,   9.10520827e-04,   1.02594141e-03,\n",
       "         1.17402314e-03,   2.29626297e-04,   2.78122158e-04,\n",
       "         1.66943997e-04,   1.44848282e-03,   1.72387126e-04,\n",
       "         2.65355527e-04,   3.18002447e-04,   7.66478257e-04,\n",
       "         8.27806840e-04,   2.30983995e-03,   2.02580791e-03,\n",
       "         8.57384560e-04,   2.98444904e-03,   2.57931876e-04,\n",
       "         2.19915803e-03,   2.10825425e-04,   1.66745996e-03,\n",
       "         2.47891788e-03,   9.97992129e-04,   1.11349428e-03,\n",
       "         2.65554929e-04,   2.22611858e-04,   2.13391656e-04,\n",
       "         1.58433877e-04,   1.20688338e-04,   2.70868684e-03,\n",
       "         2.10795229e-03,   2.36646077e-04,   1.97434298e-04,\n",
       "         1.60795529e-04,   2.04597816e-04,   7.76719183e-04,\n",
       "         8.49512638e-04,   3.14951513e-04,   1.57674774e-03,\n",
       "         2.48720344e-04,   1.54358027e-04,   3.34561312e-04,\n",
       "         1.27679687e-04,   1.41630893e-03,   2.73686805e-04,\n",
       "         1.26100784e-03,   5.46852724e-04,   8.45854996e-04,\n",
       "         2.50193020e-04,   1.72353887e-04,   1.78001615e-04,\n",
       "         5.32654017e-04,   1.69803751e-04,   5.61954637e-04,\n",
       "         1.92755291e-04,   2.11041485e-04,   3.82166609e-04,\n",
       "         2.05439163e-04,   2.16508359e-04,   1.38344582e-04,\n",
       "         2.68976744e-03,   4.80382133e-04,   2.87812079e-04,\n",
       "         6.83771768e-04,   2.28749216e-03,   2.03722265e-04,\n",
       "         8.56449418e-04,   4.03749646e-04,   1.79794192e-04,\n",
       "         1.21274895e-04,   1.32885365e-03,   2.27858375e-04,\n",
       "         1.11966994e-04,   1.54747139e-04,   1.03960415e-03,\n",
       "         1.46074916e-03,   2.27808176e-03,   1.24488169e-04,\n",
       "         8.66687323e-04,   5.23341151e-04,   2.11344710e-04,\n",
       "         2.72958422e-03,   1.07393135e-04,   7.84693109e-05,\n",
       "         9.12552175e-04,   7.92812526e-05,   1.12838490e-04,\n",
       "         6.69275859e-04,   1.12815813e-04,   1.51788573e-04,\n",
       "         8.31007134e-05,   1.56041587e-04,   1.44166090e-04,\n",
       "         9.18224551e-05,   6.84014364e-04,   9.94508316e-05,\n",
       "         2.75085590e-03,   1.73415004e-04,   8.17072684e-04,\n",
       "         1.09772576e-04,   7.56187676e-05,   1.35446670e-04,\n",
       "         2.22083910e-04,   1.08862305e-03,   6.66579856e-04,\n",
       "         7.85118476e-04,   8.89005138e-04,   7.35538420e-04,\n",
       "         1.41837721e-03,   6.74223990e-04,   8.35114282e-04,\n",
       "         1.65446336e-04,   9.87474602e-04,   2.02140032e-04,\n",
       "         1.70121546e-04,   7.78166051e-04,   5.69939604e-04,\n",
       "         2.15030158e-04,   1.90301390e-04,   1.24635960e-04,\n",
       "         5.82873529e-04,   1.36294969e-04,   9.17455182e-04,\n",
       "         1.10453665e-03,   1.23277574e-04,   1.20682615e-04,\n",
       "         1.37395712e-04,   1.21956730e-03,   8.16930249e-04,\n",
       "         9.21610462e-04,   1.44966140e-04,   1.11567795e-04,\n",
       "         1.69802391e-04,   1.52796370e-04,   1.68311375e-03,\n",
       "         2.77885260e-03,   1.24830514e-04,   1.59078104e-04,\n",
       "         2.45864924e-03,   1.31130198e-04,   1.55834759e-04,\n",
       "         1.60124424e-04,   1.31143976e-04,   1.01890371e-03,\n",
       "         1.50241832e-04,   1.27164780e-04,   1.54794086e-04,\n",
       "         1.31672857e-04,   9.40666565e-05,   1.42600995e-04,\n",
       "         1.19777334e-04,   1.27181803e-04,   9.56890786e-04,\n",
       "         8.77496001e-04,   1.57200340e-04,   2.06714165e-04,\n",
       "         2.85122357e-03,   1.93672112e-04,   1.11938823e-03,\n",
       "         1.37214999e-03,   3.03628507e-03,   2.42364871e-03,\n",
       "         1.13603129e-03,   9.25621330e-04,   2.26277632e-03,\n",
       "         2.61156844e-03,   1.16064241e-04,   1.10989338e-04,\n",
       "         1.11313530e-04,   8.31751321e-05,   1.69731566e-03,\n",
       "         2.82961448e-03,   1.46594300e-04,   2.46001077e-04,\n",
       "         1.59067411e-04,   2.05886168e-04,   1.05657885e-04,\n",
       "         1.43332735e-04,   9.98396618e-05,   1.17941130e-04,\n",
       "         8.93355792e-05,   1.37462016e-04,   1.55534730e-04,\n",
       "         1.03435951e-04,   1.21804720e-04,   9.20549426e-05,\n",
       "         2.19129765e-04,   1.45597577e-04,   1.39790891e-04,\n",
       "         1.21682253e-04,   9.94820723e-05,   1.30978511e-04,\n",
       "         1.33112660e-04,   8.97622237e-05,   7.35029298e-05,\n",
       "         1.47894573e-04,   1.25501420e-04,   9.34481789e-05,\n",
       "         9.85462992e-05,   1.23469902e-04,   1.79987888e-04,\n",
       "         9.62562679e-05,   1.36298845e-04,   7.16066959e-04,\n",
       "         1.07162193e-03,   1.59040261e-04,   2.27520021e-03,\n",
       "         2.03212787e-04,   1.59415317e-04,   1.11840460e-04,\n",
       "         1.34325070e-03,   9.10509401e-04,   1.08859741e-04,\n",
       "         1.11506886e-04,   9.85818905e-05,   1.01153183e-04,\n",
       "         1.43059013e-04,   1.00207618e-04,   1.84688564e-04,\n",
       "         2.19935043e-04,   4.68588110e-04,   1.08950877e-04,\n",
       "         2.37772666e-03,   2.17114557e-04,   1.52406688e-04,\n",
       "         2.12573953e-04,   1.70345543e-04,   1.07487131e-04,\n",
       "         3.04902098e-03,   1.17099001e-04,   1.49379073e-04,\n",
       "         7.23315927e-05,   3.11368655e-03,   1.26027436e-03,\n",
       "         7.56343844e-05,   1.59518718e-04,   1.36326105e-04,\n",
       "         1.26273667e-04,   1.48346739e-04,   2.19309392e-04,\n",
       "         6.63961074e-04,   6.81776462e-04,   3.26745124e-03,\n",
       "         8.96417932e-04,   8.71321998e-04,   5.78765312e-04,\n",
       "         1.07654897e-03,   3.72826458e-04,   1.70153594e-04,\n",
       "         1.20004232e-04,   1.88426425e-03,   1.51257089e-04,\n",
       "         2.08886343e-04,   1.35681629e-04,   1.56113305e-04,\n",
       "         1.24206888e-04,   1.98463421e-04,   1.24600426e-04,\n",
       "         1.41793138e-04,   1.97091648e-03,   1.01334055e-03,\n",
       "         9.85226165e-04,   1.09146431e-03,   1.04262901e-03,\n",
       "         1.28563145e-04,   2.01692897e-04,   1.15277710e-03,\n",
       "         2.05538489e-04,   2.12711832e-03,   3.28393204e-03,\n",
       "         2.03371731e-04,   1.56873964e-03,   1.21083724e-03,\n",
       "         2.08818210e-04,   1.61365091e-04,   1.30987229e-04,\n",
       "         1.37380992e-04,   1.58313140e-04,   9.80143063e-04,\n",
       "         1.34605332e-04,   7.58278687e-04,   6.22569460e-04,\n",
       "         3.00594602e-04,   2.45104710e-04,   3.99341944e-04,\n",
       "         1.04433424e-03,   7.17687843e-04,   1.43996842e-04,\n",
       "         7.65930192e-04,   2.05748080e-04,   3.12924935e-04,\n",
       "         1.04761787e-03,   1.04849444e-03,   1.97141932e-04,\n",
       "         1.86208580e-04,   2.76930269e-04,   5.20909515e-04,\n",
       "         2.93822437e-04,   1.35163986e-04,   1.52329808e-04,\n",
       "         1.47485068e-04,   1.35624972e-04,   1.10361461e-04,\n",
       "         9.09191154e-04,   1.43580756e-04,   1.43915078e-03,\n",
       "         2.50357017e-03,   1.37422002e-03,   9.93070284e-05,\n",
       "         2.52203152e-04,   1.00115082e-03,   1.17732811e-03,\n",
       "         1.67071600e-04,   9.96771491e-04,   1.58826485e-04,\n",
       "         2.22392790e-03,   1.30557215e-03,   8.04195514e-04,\n",
       "         6.39429481e-04,   6.92476965e-04,   1.17715796e-03,\n",
       "         2.25703051e-04,   3.26548596e-04,   1.87569127e-04,\n",
       "         2.52035092e-04,   1.35953444e-04,   3.18791482e-03,\n",
       "         1.31620455e-04,   4.50672801e-04,   2.47610711e-04,\n",
       "         1.16898999e-04,   2.58401343e-04,   1.37966724e-04,\n",
       "         1.14779607e-04,   6.93499196e-04,   9.56415935e-04,\n",
       "         7.56399652e-04,   2.63673206e-03,   1.39231756e-04,\n",
       "         9.82668123e-05,   7.59839014e-04,   2.22364891e-04,\n",
       "         1.21771151e-04,   8.92311375e-05,   1.44043101e-04,\n",
       "         1.51924787e-04,   3.75609904e-04,   2.00964548e-04,\n",
       "         1.26625341e-04,   1.07543738e-04,   1.13136226e-04,\n",
       "         1.06967815e-04,   1.05879848e-04,   1.44008254e-04,\n",
       "         9.74052397e-05,   1.48099110e-04,   9.57997543e-05,\n",
       "         3.24243301e-03,   1.55381504e-04,   1.29143238e-04,\n",
       "         2.36081774e-03,   1.60034464e-04,   1.03742275e-04,\n",
       "         1.25973663e-03,   7.66503468e-04,   3.09815177e-04,\n",
       "         1.45975058e-04,   9.39404784e-05,   2.91447456e-03,\n",
       "         2.08263693e-04,   1.17243647e-04,   1.00335612e-04,\n",
       "         1.28244699e-03,   2.04365115e-04,   1.41109473e-04,\n",
       "         6.05807871e-04,   2.55238409e-04,   1.56563171e-04,\n",
       "         9.86851036e-04,   1.52590383e-04,   3.40770567e-04,\n",
       "         1.44812453e-04,   6.53014662e-04,   1.24342635e-03,\n",
       "         2.13305259e-04,   9.35914287e-04,   6.89586630e-04,\n",
       "         6.64680428e-04,   1.00035757e-03,   2.36632495e-03,\n",
       "         1.02798356e-04,   2.01557912e-04,   1.46225708e-04,\n",
       "         1.91019157e-03,   1.35461754e-03,   2.20753533e-03,\n",
       "         2.72143511e-04,   7.19717166e-04,   1.09016793e-03,\n",
       "         8.99730861e-04,   1.40251330e-04,   1.17093548e-03,\n",
       "         4.50549911e-04,   3.50496525e-04,   6.32973913e-04,\n",
       "         1.00115172e-03,   8.01386136e-04,   9.92164219e-04,\n",
       "         8.37856697e-04,   3.72739679e-04,   4.47805572e-04,\n",
       "         1.07637671e-03,   3.62750226e-04,   6.54330030e-04,\n",
       "         1.52841228e-03,   6.16679321e-04,   4.93377641e-04,\n",
       "         4.18183789e-04,   3.50347468e-04,   7.88548818e-04,\n",
       "         7.02056708e-04,   4.44216089e-04,   4.10148395e-04,\n",
       "         3.32329104e-04,   2.21770137e-04,   3.29752104e-04,\n",
       "         4.85612150e-04,   6.52363954e-04,   2.79744473e-04,\n",
       "         6.19709936e-04,   4.16604277e-04,   3.66054041e-04,\n",
       "         2.10186938e-03,   2.63743882e-04,   3.26898495e-04,\n",
       "         2.20006688e-03,   3.40371971e-04,   9.08489590e-04,\n",
       "         6.30227843e-04,   7.67581283e-04,   9.56173287e-04,\n",
       "         8.60198380e-04,   8.54032498e-05,   7.85380984e-04,\n",
       "         1.55901609e-04,   8.63537762e-04,   7.98474999e-04,\n",
       "         1.03853778e-04,   1.59540506e-03,   1.91416709e-04,\n",
       "         5.75601127e-05,   2.77391389e-03,   4.52091769e-04,\n",
       "         2.10497554e-04,   6.11035266e-04,   4.47243672e-04,\n",
       "         2.68118611e-04,   2.90247755e-04,   1.66178504e-03,\n",
       "         5.99240972e-04,   3.85128874e-04,   8.06519431e-04,\n",
       "         3.86367870e-04,   1.49419230e-04,   9.70941126e-04,\n",
       "         1.02130766e-04,   1.14129425e-04,   1.51727375e-04,\n",
       "         1.15497769e-04,   1.12770631e-04,   1.77285633e-04,\n",
       "         8.89998849e-04,   9.43878345e-04,   1.43634760e-04,\n",
       "         9.14701779e-05,   9.47916185e-05,   1.43776285e-04,\n",
       "         2.58199583e-04,   1.39049248e-04,   1.23510570e-04,\n",
       "         2.90292930e-03,   1.66602831e-04,   2.53760265e-03,\n",
       "         1.32162654e-04,   1.98210732e-04,   1.60773418e-04,\n",
       "         1.42947615e-04,   1.72276537e-03,   3.00081539e-03,\n",
       "         2.29593978e-03,   2.39572605e-03,   1.13003233e-04,\n",
       "         1.92167570e-04,   7.74638332e-05,   7.36492515e-04,\n",
       "         7.85693669e-04,   1.22093743e-03,   1.47696853e-03,\n",
       "         8.17158528e-04,   2.65260017e-03,   6.66134605e-04,\n",
       "         2.47164414e-04,   1.04208944e-03,   2.11178643e-03,\n",
       "         7.86230672e-04,   3.49220982e-04,   1.59341752e-04,\n",
       "         4.68320363e-04,   5.06395272e-04,   4.59660671e-04,\n",
       "         4.28438389e-04,   3.29263243e-04,   4.85424777e-04,\n",
       "         9.25327110e-04,   2.64160787e-04,   7.68366968e-04,\n",
       "         5.86460140e-04,   3.89327421e-04,   7.34432913e-04,\n",
       "         2.16941325e-04,   3.27734115e-04,   7.00792712e-04,\n",
       "         4.68224600e-04,   6.07449561e-04,   2.43256333e-04,\n",
       "         7.15377233e-04,   3.10558149e-04,   1.19192865e-03,\n",
       "         4.31953940e-04,   7.84024155e-04,   2.22717325e-04,\n",
       "         3.81426583e-04,   4.26224948e-04,   4.57565176e-04,\n",
       "         2.03698826e-04,   2.52985061e-04,   4.10216858e-04,\n",
       "         5.08216269e-04,   3.81041156e-04,   7.75459721e-04,\n",
       "         6.12838635e-04,   8.25366980e-04,   5.32157459e-04,\n",
       "         4.54033172e-04,   4.85109698e-04,   3.87981837e-04,\n",
       "         4.53383537e-04,   2.79570909e-04,   8.98227085e-04,\n",
       "         3.95074131e-04,   3.22500560e-04,   3.84254839e-04,\n",
       "         5.33354321e-04,   4.81131985e-04,   1.47309647e-04,\n",
       "         2.18468265e-03,   2.51468881e-04,   5.29173585e-04,\n",
       "         1.06978816e-03,   7.99557619e-04,   1.68807983e-04,\n",
       "         3.48408945e-04,   4.38292450e-04,   4.73092325e-04,\n",
       "         7.43180055e-04,   1.07761147e-03,   1.15967583e-03,\n",
       "         3.21288980e-04,   7.62985676e-04,   5.85135625e-04,\n",
       "         1.57574240e-03,   6.44640516e-04,   2.45777242e-04,\n",
       "         2.93474534e-04,   4.23318833e-04,   4.30375589e-04,\n",
       "         6.95205595e-04,   8.37506817e-04,   2.64629556e-04,\n",
       "         1.51517748e-03,   3.19597683e-04,   2.49433691e-04,\n",
       "         5.57720735e-04,   3.70185414e-04,   3.74311760e-04,\n",
       "         5.33352911e-04,   2.30056868e-04,   6.42253740e-04,\n",
       "         5.18469590e-04,   3.14526132e-04,   6.94922749e-04,\n",
       "         2.74257617e-04,   2.78856784e-04,   6.84109227e-04,\n",
       "         1.14805264e-03,   1.42680312e-03,   3.55399167e-04,\n",
       "         4.05692536e-04,   7.08276128e-04,   5.77177064e-04,\n",
       "         4.21065839e-04,   2.90895496e-04,   8.90538132e-04,\n",
       "         7.53671837e-04,   7.45749814e-04,   3.17585680e-04,\n",
       "         7.10758390e-04,   4.45949169e-04,   4.13805548e-04,\n",
       "         9.88482130e-04,   1.34110738e-03,   6.27305418e-04,\n",
       "         2.83621120e-04,   8.24701542e-04,   2.99231008e-04,\n",
       "         2.49330006e-04,   3.90273943e-04,   6.56373453e-04,\n",
       "         3.70137548e-04,   9.10522339e-04,   3.47423311e-04,\n",
       "         3.78749959e-04,   3.20372650e-04,   1.02661348e-03,\n",
       "         1.24618061e-03,   6.41196760e-04,   1.52014331e-03,\n",
       "         9.82289764e-04,   1.46151730e-03,   1.97089632e-03,\n",
       "         3.86119948e-04,   5.30609936e-04,   2.42566727e-04,\n",
       "         1.90755653e-04,   2.77381423e-04,   2.56627843e-04,\n",
       "         4.85408190e-04,   3.00752684e-04,   3.56819867e-04,\n",
       "         3.88026532e-04,   3.17898787e-04,   3.03093379e-04,\n",
       "         4.82044764e-04,   5.03346367e-04,   6.16126033e-04,\n",
       "         1.02852998e-03,   2.70868649e-04,   1.62777672e-04,\n",
       "         2.02148684e-04,   9.00946840e-04,   1.82812571e-03,\n",
       "         1.72150242e-04,   7.06631690e-04,   1.40886770e-03,\n",
       "         2.70882525e-04,   2.40616385e-02,   7.99269816e-03,\n",
       "         3.94489713e-03,   1.06011646e-02,   6.05215745e-04])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_attribs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['female', 'male']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(cat_encoder.categories_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.096207202849624973, 'female'),\n",
       " (0.084202142430869792, 'male'),\n",
       " (0.080260640743907097, 'Fare'),\n",
       " (0.073587746250216551, 'Age'),\n",
       " (0.038043711197780189, 'Pclass'),\n",
       " (0.025707805566393748, 'SibSp'),\n",
       " (0.021836871981943964, 'Parch')]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = cat_pipeline.named_steps[\"cat_encoder\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some DL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\SAMSEP~1\\AppData\\Local\\Temp\\tmpb43ef47k\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x00000142FF6A2DD8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_tf_random_seed': 42, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_session_config': None, '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': 'C:\\\\Users\\\\SAMSEP~1\\\\AppData\\\\Local\\\\Temp\\\\tmpb43ef47k'}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "WARNING:tensorflow:From C:\\Users\\SamSepiol\\Miniconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:642: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "WARNING:tensorflow:Casting <dtype: 'int64'> labels to bool.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\SAMSEP~1\\AppData\\Local\\Temp\\tmpb43ef47k\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.689126, step = 1\n",
      "INFO:tensorflow:global_step/sec: 263.976\n",
      "INFO:tensorflow:loss = 0.454021, step = 101 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.55\n",
      "INFO:tensorflow:loss = 0.269332, step = 201 (0.363 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.817\n",
      "INFO:tensorflow:loss = 0.243271, step = 301 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.19\n",
      "INFO:tensorflow:loss = 0.268852, step = 401 (0.373 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.191\n",
      "INFO:tensorflow:loss = 0.188705, step = 501 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.061\n",
      "INFO:tensorflow:loss = 0.0847653, step = 601 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 272.849\n",
      "INFO:tensorflow:loss = 0.0376033, step = 701 (0.368 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.386\n",
      "INFO:tensorflow:loss = 0.0410752, step = 801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.855\n",
      "INFO:tensorflow:loss = 0.0850663, step = 901 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.003\n",
      "INFO:tensorflow:loss = 0.0306664, step = 1001 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.592\n",
      "INFO:tensorflow:loss = 0.0140474, step = 1101 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.17\n",
      "INFO:tensorflow:loss = 0.0365825, step = 1201 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.995\n",
      "INFO:tensorflow:loss = 0.00951178, step = 1301 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.504\n",
      "INFO:tensorflow:loss = 0.0339332, step = 1401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.802\n",
      "INFO:tensorflow:loss = 0.00600894, step = 1501 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.063\n",
      "INFO:tensorflow:loss = 0.00281397, step = 1601 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.928\n",
      "INFO:tensorflow:loss = 0.0292179, step = 1701 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 274.245\n",
      "INFO:tensorflow:loss = 0.00186632, step = 1801 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.804\n",
      "INFO:tensorflow:loss = 0.00377835, step = 1901 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.34\n",
      "INFO:tensorflow:loss = 0.00127459, step = 2001 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.239\n",
      "INFO:tensorflow:loss = 0.00185805, step = 2101 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.059\n",
      "INFO:tensorflow:loss = 0.0103789, step = 2201 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.398\n",
      "INFO:tensorflow:loss = 0.0253783, step = 2301 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.666\n",
      "INFO:tensorflow:loss = 0.00648151, step = 2401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.396\n",
      "INFO:tensorflow:loss = 0.000885091, step = 2501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.471\n",
      "INFO:tensorflow:loss = 0.00123518, step = 2601 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 273.266\n",
      "INFO:tensorflow:loss = 0.0172038, step = 2701 (0.367 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.934\n",
      "INFO:tensorflow:loss = 0.00110413, step = 2801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.349\n",
      "INFO:tensorflow:loss = 0.00240117, step = 2901 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.815\n",
      "INFO:tensorflow:loss = 0.0254726, step = 3001 (0.379 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.878\n",
      "INFO:tensorflow:loss = 0.00228077, step = 3101 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.763\n",
      "INFO:tensorflow:loss = 0.0178693, step = 3201 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.288\n",
      "INFO:tensorflow:loss = 0.0111184, step = 3301 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.587\n",
      "INFO:tensorflow:loss = 0.0117029, step = 3401 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.245\n",
      "INFO:tensorflow:loss = 0.0200422, step = 3501 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.277\n",
      "INFO:tensorflow:loss = 0.0118441, step = 3601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.852\n",
      "INFO:tensorflow:loss = 0.000559559, step = 3701 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.941\n",
      "INFO:tensorflow:loss = 0.000341986, step = 3801 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.29\n",
      "INFO:tensorflow:loss = 0.000758471, step = 3901 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.41\n",
      "INFO:tensorflow:loss = 0.00387444, step = 4001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.698\n",
      "INFO:tensorflow:loss = 0.0279859, step = 4101 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.388\n",
      "INFO:tensorflow:loss = 0.000453553, step = 4201 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.921\n",
      "INFO:tensorflow:loss = 0.0382957, step = 4301 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.222\n",
      "INFO:tensorflow:loss = 0.00574273, step = 4401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.267\n",
      "INFO:tensorflow:loss = 0.000766704, step = 4501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.116\n",
      "INFO:tensorflow:loss = 0.000614302, step = 4601 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 269.46\n",
      "INFO:tensorflow:loss = 0.00207264, step = 4701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.926\n",
      "INFO:tensorflow:loss = 0.00588488, step = 4801 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.943\n",
      "INFO:tensorflow:loss = 0.00825662, step = 4901 (0.374 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.709\n",
      "INFO:tensorflow:loss = 0.000395488, step = 5001 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 266.476\n",
      "INFO:tensorflow:loss = 0.000456191, step = 5101 (0.375 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.67\n",
      "INFO:tensorflow:loss = 0.0018328, step = 5201 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.611\n",
      "INFO:tensorflow:loss = 0.0142421, step = 5301 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.088\n",
      "INFO:tensorflow:loss = 0.000447886, step = 5401 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.015\n",
      "INFO:tensorflow:loss = 0.000459147, step = 5501 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.218\n",
      "INFO:tensorflow:loss = 0.0182124, step = 5601 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 267.839\n",
      "INFO:tensorflow:loss = 0.00427309, step = 5701 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.77\n",
      "INFO:tensorflow:loss = 0.0020997, step = 5801 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.979\n",
      "INFO:tensorflow:loss = 0.0147613, step = 5901 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.147\n",
      "INFO:tensorflow:loss = 0.000478522, step = 6001 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.377\n",
      "INFO:tensorflow:loss = 0.00029579, step = 6101 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.069\n",
      "INFO:tensorflow:loss = 0.00045375, step = 6201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.335\n",
      "INFO:tensorflow:loss = 0.00473505, step = 6301 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.04\n",
      "INFO:tensorflow:loss = 0.00452449, step = 6401 (0.380 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 265.888\n",
      "INFO:tensorflow:loss = 0.0156593, step = 6501 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.412\n",
      "INFO:tensorflow:loss = 0.00261877, step = 6601 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.616\n",
      "INFO:tensorflow:loss = 0.000441592, step = 6701 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.692\n",
      "INFO:tensorflow:loss = 0.0294845, step = 6801 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.733\n",
      "INFO:tensorflow:loss = 0.0072922, step = 6901 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 218.466\n",
      "INFO:tensorflow:loss = 0.039301, step = 7001 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.554\n",
      "INFO:tensorflow:loss = 0.000327751, step = 7101 (0.459 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.548\n",
      "INFO:tensorflow:loss = 0.000248132, step = 7201 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.841\n",
      "INFO:tensorflow:loss = 0.00521558, step = 7301 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 263.153\n",
      "INFO:tensorflow:loss = 0.00415564, step = 7401 (0.380 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.739\n",
      "INFO:tensorflow:loss = 0.0358767, step = 7501 (0.376 sec)\n",
      "INFO:tensorflow:global_step/sec: 276.645\n",
      "INFO:tensorflow:loss = 0.000393739, step = 7601 (0.360 sec)\n",
      "INFO:tensorflow:global_step/sec: 277.675\n",
      "INFO:tensorflow:loss = 0.000309473, step = 7701 (0.361 sec)\n",
      "INFO:tensorflow:global_step/sec: 270.786\n",
      "INFO:tensorflow:loss = 0.0104527, step = 7801 (0.369 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.317\n",
      "INFO:tensorflow:loss = 0.0208577, step = 7901 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.465\n",
      "INFO:tensorflow:loss = 0.0204523, step = 8001 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 271.016\n",
      "INFO:tensorflow:loss = 0.000220562, step = 8101 (0.370 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.71\n",
      "INFO:tensorflow:loss = 0.000163845, step = 8201 (0.372 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.42\n",
      "INFO:tensorflow:loss = 0.0316974, step = 8301 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.954\n",
      "INFO:tensorflow:loss = 0.0195923, step = 8401 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.217\n",
      "INFO:tensorflow:loss = 0.000214047, step = 8501 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.639\n",
      "INFO:tensorflow:loss = 0.000281976, step = 8601 (0.388 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.075\n",
      "INFO:tensorflow:loss = 0.000385181, step = 8701 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.011\n",
      "INFO:tensorflow:loss = 0.000350254, step = 8801 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 262.553\n",
      "INFO:tensorflow:loss = 0.00808228, step = 8901 (0.381 sec)\n",
      "INFO:tensorflow:global_step/sec: 279.887\n",
      "INFO:tensorflow:loss = 0.00016423, step = 9001 (0.357 sec)\n",
      "INFO:tensorflow:global_step/sec: 275.03\n",
      "INFO:tensorflow:loss = 0.000483443, step = 9101 (0.364 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.81\n",
      "INFO:tensorflow:loss = 0.0012019, step = 9201 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.142\n",
      "INFO:tensorflow:loss = 0.0044174, step = 9301 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.081\n",
      "INFO:tensorflow:loss = 0.000873735, step = 9401 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.803\n",
      "INFO:tensorflow:loss = 0.00359105, step = 9501 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.25\n",
      "INFO:tensorflow:loss = 0.00147343, step = 9601 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.89\n",
      "INFO:tensorflow:loss = 0.00077363, step = 9701 (0.389 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.014\n",
      "INFO:tensorflow:loss = 0.0151544, step = 9801 (0.382 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.394\n",
      "INFO:tensorflow:loss = 0.00834111, step = 9901 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.408\n",
      "INFO:tensorflow:loss = 0.000193037, step = 10001 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.586\n",
      "INFO:tensorflow:loss = 0.000803955, step = 10101 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.019\n",
      "INFO:tensorflow:loss = 0.0168749, step = 10201 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.476\n",
      "INFO:tensorflow:loss = 0.0333108, step = 10301 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.038\n",
      "INFO:tensorflow:loss = 0.00040493, step = 10401 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.15\n",
      "INFO:tensorflow:loss = 0.0126694, step = 10501 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.889\n",
      "INFO:tensorflow:loss = 0.000112834, step = 10601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.855\n",
      "INFO:tensorflow:loss = 0.012796, step = 10701 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.232\n",
      "INFO:tensorflow:loss = 0.000161437, step = 10801 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.394\n",
      "INFO:tensorflow:loss = 0.000137986, step = 10901 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.248\n",
      "INFO:tensorflow:loss = 0.000128078, step = 11001 (0.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.062\n",
      "INFO:tensorflow:loss = 0.000925879, step = 11101 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.207\n",
      "INFO:tensorflow:loss = 0.000288833, step = 11201 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.984\n",
      "INFO:tensorflow:loss = 0.000162401, step = 11301 (0.431 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.616\n",
      "INFO:tensorflow:loss = 0.000214378, step = 11401 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.176\n",
      "INFO:tensorflow:loss = 0.00471393, step = 11501 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.061\n",
      "INFO:tensorflow:loss = 0.00170784, step = 11601 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.014\n",
      "INFO:tensorflow:loss = 0.00173934, step = 11701 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.607\n",
      "INFO:tensorflow:loss = 0.0186056, step = 11801 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.349\n",
      "INFO:tensorflow:loss = 0.0350622, step = 11901 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.503\n",
      "INFO:tensorflow:loss = 0.0337653, step = 12001 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.897\n",
      "INFO:tensorflow:loss = 0.000217417, step = 12101 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.443\n",
      "INFO:tensorflow:loss = 9.10635e-05, step = 12201 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.135\n",
      "INFO:tensorflow:loss = 0.000145456, step = 12301 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.063\n",
      "INFO:tensorflow:loss = 0.000132035, step = 12401 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.032\n",
      "INFO:tensorflow:loss = 0.000897016, step = 12501 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.275\n",
      "INFO:tensorflow:loss = 0.000290837, step = 12601 (0.461 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.017\n",
      "INFO:tensorflow:loss = 0.0227664, step = 12701 (0.456 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.541\n",
      "INFO:tensorflow:loss = 0.00163443, step = 12801 (0.442 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.902\n",
      "INFO:tensorflow:loss = 0.00153762, step = 12901 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.386\n",
      "INFO:tensorflow:loss = 0.000159929, step = 13001 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.356\n",
      "INFO:tensorflow:loss = 0.000165172, step = 13101 (0.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.572\n",
      "INFO:tensorflow:loss = 0.000175898, step = 13201 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.838\n",
      "INFO:tensorflow:loss = 0.00383336, step = 13301 (0.466 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.587\n",
      "INFO:tensorflow:loss = 0.000100647, step = 13401 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 264.512\n",
      "INFO:tensorflow:loss = 0.000285758, step = 13501 (0.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.092\n",
      "INFO:tensorflow:loss = 0.000117618, step = 13601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 268.531\n",
      "INFO:tensorflow:loss = 8.6627e-05, step = 13701 (0.371 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.858\n",
      "INFO:tensorflow:loss = 0.0123422, step = 13801 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.993\n",
      "INFO:tensorflow:loss = 0.000122185, step = 13901 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.834\n",
      "INFO:tensorflow:loss = 0.0190694, step = 14001 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.43\n",
      "INFO:tensorflow:loss = 0.00520971, step = 14101 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.599\n",
      "INFO:tensorflow:loss = 0.000108662, step = 14201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.778\n",
      "INFO:tensorflow:loss = 0.000119099, step = 14301 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.618\n",
      "INFO:tensorflow:loss = 0.000146414, step = 14401 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.157\n",
      "INFO:tensorflow:loss = 0.000120691, step = 14501 (0.477 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.00014846, step = 14601 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.808\n",
      "INFO:tensorflow:loss = 0.00017592, step = 14701 (0.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.253\n",
      "INFO:tensorflow:loss = 0.000135205, step = 14801 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.408\n",
      "INFO:tensorflow:loss = 9.81083e-05, step = 14901 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.994\n",
      "INFO:tensorflow:loss = 0.00648775, step = 15001 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.686\n",
      "INFO:tensorflow:loss = 0.000469615, step = 15101 (0.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.599\n",
      "INFO:tensorflow:loss = 0.00138795, step = 15201 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.335\n",
      "INFO:tensorflow:loss = 0.000235678, step = 15301 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.248\n",
      "INFO:tensorflow:loss = 0.0294764, step = 15401 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.265\n",
      "INFO:tensorflow:loss = 0.00112136, step = 15501 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 214.618\n",
      "INFO:tensorflow:loss = 8.41586e-05, step = 15601 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.493\n",
      "INFO:tensorflow:loss = 0.00204458, step = 15701 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.683\n",
      "INFO:tensorflow:loss = 0.000115669, step = 15801 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 216.244\n",
      "INFO:tensorflow:loss = 0.000134832, step = 15901 (0.463 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.465\n",
      "INFO:tensorflow:loss = 0.000695155, step = 16001 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.617\n",
      "INFO:tensorflow:loss = 0.00140096, step = 16101 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.472\n",
      "INFO:tensorflow:loss = 0.000232992, step = 16201 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 219.097\n",
      "INFO:tensorflow:loss = 0.00011379, step = 16301 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.505\n",
      "INFO:tensorflow:loss = 7.95306e-05, step = 16401 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.405\n",
      "INFO:tensorflow:loss = 0.00123935, step = 16501 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 224.757\n",
      "INFO:tensorflow:loss = 0.000154436, step = 16601 (0.445 sec)\n",
      "INFO:tensorflow:global_step/sec: 221.272\n",
      "INFO:tensorflow:loss = 0.000224465, step = 16701 (0.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.629\n",
      "INFO:tensorflow:loss = 9.07353e-05, step = 16801 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.114\n",
      "INFO:tensorflow:loss = 0.00014213, step = 16901 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.805\n",
      "INFO:tensorflow:loss = 0.0231127, step = 17001 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.232\n",
      "INFO:tensorflow:loss = 6.82174e-05, step = 17101 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.919\n",
      "INFO:tensorflow:loss = 7.04264e-05, step = 17201 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.56\n",
      "INFO:tensorflow:loss = 0.000108393, step = 17301 (0.434 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.139\n",
      "INFO:tensorflow:loss = 0.000554032, step = 17401 (0.439 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.758\n",
      "INFO:tensorflow:loss = 0.0103751, step = 17501 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.181\n",
      "INFO:tensorflow:loss = 0.000104557, step = 17601 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.561\n",
      "INFO:tensorflow:loss = 0.00277014, step = 17701 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 265.175\n",
      "INFO:tensorflow:loss = 0.000154722, step = 17801 (0.377 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.653\n",
      "INFO:tensorflow:loss = 0.0120579, step = 17901 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 261.179\n",
      "INFO:tensorflow:loss = 7.98278e-05, step = 18001 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.945\n",
      "INFO:tensorflow:loss = 0.0161195, step = 18101 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.458\n",
      "INFO:tensorflow:loss = 0.000108409, step = 18201 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.957\n",
      "INFO:tensorflow:loss = 0.000104837, step = 18301 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.198\n",
      "INFO:tensorflow:loss = 0.00243066, step = 18401 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.628\n",
      "INFO:tensorflow:loss = 0.00134465, step = 18501 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.466\n",
      "INFO:tensorflow:loss = 0.00917173, step = 18601 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.253\n",
      "INFO:tensorflow:loss = 6.95138e-05, step = 18701 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.508\n",
      "INFO:tensorflow:loss = 0.000122652, step = 18801 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.757\n",
      "INFO:tensorflow:loss = 0.000114488, step = 18901 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.133\n",
      "INFO:tensorflow:loss = 0.017773, step = 19001 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 225.265\n",
      "INFO:tensorflow:loss = 0.00923037, step = 19101 (0.444 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.168\n",
      "INFO:tensorflow:loss = 0.000316656, step = 19201 (0.384 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.08\n",
      "INFO:tensorflow:loss = 0.00820608, step = 19301 (0.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.258\n",
      "INFO:tensorflow:loss = 0.0001311, step = 19401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.08\n",
      "INFO:tensorflow:loss = 0.000281999, step = 19501 (0.433 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.892\n",
      "INFO:tensorflow:loss = 0.000119578, step = 19601 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 260.724\n",
      "INFO:tensorflow:loss = 9.76006e-05, step = 19701 (0.383 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.775\n",
      "INFO:tensorflow:loss = 0.000113455, step = 19801 (0.386 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.825\n",
      "INFO:tensorflow:loss = 0.0285243, step = 19901 (0.387 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 20000 into C:\\Users\\SAMSEP~1\\AppData\\Local\\Temp\\tmpb43ef47k\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 8.41293e-05.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed=42) # not shown in the config\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(train_data_prepared)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,100], n_classes=2,\n",
    "                                         feature_columns=feature_cols, config=config)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf) # if TensorFlow >= 1.1\n",
    "dnn_clf.fit(train_data_prepared, train_labels, batch_size=50, steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 11)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test_data[['PassengerId', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_data.drop(['PassengerId', 'Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_prepared = full_pipeline.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 840)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_prepared.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\SAMSEP~1\\AppData\\Local\\Temp\\tmpb43ef47k\\model.ckpt-20000\n"
     ]
    }
   ],
   "source": [
    "y_pred = dnn_clf.predict(test_data_prepared) #np.array([test_data[0]], dtype=float), as_iterable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = y_pred['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set ids as PassengerId and predict survival \n",
    "ids = test_ids['PassengerId']\n",
    "\n",
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': preds })\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         1"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_model = rnd_search.best_estimator_\n",
    "\n",
    "final_predictions = final_model.predict(test_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#set the output as a dataframe and convert to csv file named submission.csv\n",
    "output = pd.DataFrame({ 'PassengerId' : ids, 'Survived': final_predictions })\n",
    "output.to_csv('submission_forest_clf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
